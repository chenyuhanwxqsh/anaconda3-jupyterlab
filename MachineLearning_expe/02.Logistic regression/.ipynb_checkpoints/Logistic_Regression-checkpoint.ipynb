{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归\n",
    "\n",
    "在本练习中，你将实现逻辑回归并将其应用于两个不同的数据集。\n",
    "\n",
    "\n",
    "# 大纲\n",
    "- [ 1 - 包 ](#1)\n",
    "- [ 2 - 逻辑回归](#2)\n",
    "  - [ 2.1 问题描述](#2.1)\n",
    "  - [ 2.2 加载与可视化数据](#2.2)\n",
    "  - [ 2.3 Sigmoid 函数](#2.3)\n",
    "  - [ 2.4 逻辑回归的损失函数](#2.4)\n",
    "  - [ 2.5 逻辑回归的梯度](#2.5)\n",
    "  - [ 2.6 通过梯度下降法学习参数](#2.6)\n",
    "  - [ 2.7 绘制决策边界](#2.7)\n",
    "  - [ 2.8 评估逻辑回归](#2.8)\n",
    "- [ 3 - 逻辑回归的正则化](#3)\n",
    "  - [ 3.1 问题描述](#3.1)\n",
    "  - [ 3.2 加载与可视化数据](#3.2)\n",
    "  - [ 3.3 特征映射](#3.3)\n",
    "  - [ 3.4 正则化逻辑回归的损失函数](#3.4)\n",
    "  - [ 3.5 正则化逻辑回归的梯度](#3.5)\n",
    "  - [ 3.6 通过梯度下降法学习参数](#3.6)\n",
    "  - [ 3.7 绘制决策边界](#3.7)\n",
    "  - [ 3.8 评估正则化逻辑回归模型](#3.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - 包\n",
    "\n",
    "首先，让我们运行下面的单元格来导入你在此分配期间需要的所有包。\n",
    "- [numpy](www.numpy.org) 是使用 Python 进行科学计算的基础包。\n",
    "- [matplotlib](http://matplotlib.org) 是一个著名的 Python 绘图库。\n",
    "-  ``utils.py`` 包含此声明的辅助函数。你无需修改此文件中的代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import copy\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - 逻辑回归\n",
    "\n",
    "在这部分练习中，你将建立一个逻辑回归模型来预测学生是否被大学录取。\n",
    "\n",
    "<a name=\"2.1\"></a>\n",
    "### 2.1 问题描述\n",
    "\n",
    "假设你是一个大学部门的管理员，并且你想根据每个申请人的两次考试成绩来确定他们的录取机会。\n",
    "* 你拥有以前申请者的历史数据，可用作逻辑回归的训练集。\n",
    "* 对于每个培训示例，你都有申请人在两次考试中的分数和录取决定。 \n",
    "* 你的任务是建立一个分类模型，根据这两个考试的分数来估计申请人的录取概率。\n",
    "\n",
    "<a name=\"2.2\"></a>\n",
    "### 2.2 加载与可视化数据\n",
    "\n",
    "首先，你将为此任务加载数据集。 \n",
    "- 如下所示， `load_dataset()` 函数将数据加载到变量 `X_train` 和 `y_train`中\n",
    "  - `X_train` 包含学生两次考试的考试成绩\n",
    "  - `y_train` 是录取决定 \n",
    "      - `y_train = 1` 表示学生已经被录取\n",
    "      - `y_train = 0` 表示学生没有被录取 \n",
    "  - `X_train` 和 `y_train` 都是 numpy 数组\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "X_train, y_train = load_data(\"data/ex2data1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看变量\n",
    "让我们更熟悉你的数据集。\n",
    "- 一个好的开始是打印出每个变量，看看它包含什么。\n",
    "\n",
    "下面的代码打印了 `X_train` 的前五个值和类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five elements in X_train are:\n",
      " [[34.62365962 78.02469282]\n",
      " [30.28671077 43.89499752]\n",
      " [35.84740877 72.90219803]\n",
      " [60.18259939 86.3085521 ]\n",
      " [79.03273605 75.34437644]]\n",
      "Type of X_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First five elements in X_train are:\\n\", X_train[:5])\n",
    "print(\"Type of X_train:\",type(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在打印 `y_train` 的前五个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five elements in y_train are:\n",
      " [0. 0. 0. 1. 1.]\n",
      "Type of y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First five elements in y_train are:\\n\", y_train[:5])\n",
    "print(\"Type of y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看变量维度\n",
    "\n",
    "另一种熟悉数据的有用方法是查看其维度。让我们打印 `X_train` 和 `y_train` 的形状，看看我们的数据集中有多少训练样例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (100, 2)\n",
      "The shape of y_train is: (100,)\n",
      "We have m = 100 training examples\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X_train is: ' + str(X_train.shape))\n",
    "print ('The shape of y_train is: ' + str(y_train.shape))\n",
    "print ('We have m = %d training examples' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 可视化你的数据\n",
    "\n",
    "在开始实现任何学习算法之前，如果可能的话，最好将数据可视化。\n",
    "- 下面的代码将数据显示在 2D 图上（如下所示），其中轴是两个考试分数，正例和负例用不同的标记显示。\n",
    "- 我们使用 `utils.py` 文件中的一个辅助函数来生成这个图。\n",
    "\n",
    "<img src=\"images/figure 1.png\" width=\"450\" height=\"450\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot examples\n",
    "plot_data(X_train, y_train[:], pos_label=\"Admitted\", neg_label=\"Not admitted\")\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Exam 2 score') \n",
    "# Set the x-axis label\n",
    "plt.xlabel('Exam 1 score') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的目标是建立一个逻辑回归模型来拟合这些数据。\n",
    "- 使用此模型，你可以根据新学生在两次考试中的成绩预测是否会被录取。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### 2.3  Sigmoid 函数\n",
    "\n",
    "回想一下，对于逻辑回归，模型表示为\n",
    "\n",
    "$$ f_{\\mathbf{w},b}(x) = g(\\mathbf{w}\\cdot \\mathbf{x} + b)$$\n",
    "其中 $g$ 是 sigmoid 函数。 sigmoid 函数的定义如下:\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "让我们先实现 sigmoid 函数，这样它就可以被这个声明的其余部分使用。\n",
    "\n",
    "<a name='ex-01'></a>\n",
    "### 练习 1\n",
    "请完成 `sigmoid` 函数来计算\n",
    "\n",
    "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "请注意\n",
    "- `z` 并不总是一个数字，也可以是一个数字数组。\n",
    "- 如果输入是一个数字数组，我们希望将 sigmoid 函数应用于输入数组中的每个值。\n",
    "\n",
    "如果你遇到困难，你可以查看下面单元格后提供的提示，以帮助你实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Args:\n",
    "        z (ndarray): A scalar, numpy array of any size.\n",
    "\n",
    "    Returns:\n",
    "        g (ndarray): sigmoid(z), with the same shape as z\n",
    "         \n",
    "    \"\"\"\n",
    "          \n",
    "    ### START CODE HERE ### \n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    ### END SOLUTION ###  \n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当你完成后，尝试在下面的单元格中调用 `sigmoid(x)` 来测试一些值。\n",
    "- 对于较大的 x 正值，sigmoid 应该接近 1，而对于较大的负值，sigmoid 应该接近 0。\n",
    "- 计算 `sigmoid(0)` 应该确切地得出 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>sigmoid(0)<b></td>\n",
    "    <td> 0.5 </td> \n",
    "  </tr>\n",
    "</table>\n",
    "    \n",
    "- 如前所述，你的代码也应该适用于向量和矩阵。对于矩阵，你的函数应该对每个元素执行 sigmoid 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([ -1, 0, 1, 2]) = [0.26894142 0.5        0.73105858 0.88079708]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([ -1, 0, 1, 2]) = \" + str(sigmoid(np.array([-1, 0, 1, 2]))))\n",
    "\n",
    "# UNIT TESTS\n",
    "from public_tests import *\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><b>sigmoid([-1, 0, 1, 2])<b></td> \n",
    "    <td>[0.26894142        0.5           0.73105858        0.88079708]</td> \n",
    "  </tr>    \n",
    "  \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.4\"></a>\n",
    "### 2.4 逻辑回归的损失函数\n",
    "\n",
    "在本节中，你将实现逻辑回归的损失函数\n",
    "\n",
    "<a name='ex-02'></a>\n",
    "### 练习 2\n",
    "\n",
    "请使用下面的等式，完成 `compute_cost` 函数\n",
    "\n",
    "回想一下，对于逻辑回归，损失函数的形式为\n",
    "\n",
    "$$ J(\\mathbf{w},b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) \\right] \\tag{1}$$\n",
    "\n",
    "其中\n",
    "* m 是数据集中训练样例的数量\n",
    "\n",
    "\n",
    "* $loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)})$ 是单个数据点的损失，即 - \n",
    "\n",
    "    $$loss(f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}), y^{(i)}) = (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\tag{2}$$\n",
    "    \n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ 是模型的预测， 其中 $y^{(i)}$ 是实际的标签\n",
    "\n",
    "*  $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(\\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b)$ 其中函数 $g$ 是 sigmoid 函数.\n",
    "    * 在计算 $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = g(z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}))$ 之前，先计算一个中间变量可能会有所帮助： $z_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) = \\mathbf{w} \\cdot \\mathbf{x^{(i)}} + b = w_0x^{(i)}_0 + ... + w_{n-1}x^{(i)}_{n-1} + b$ 其中 $n$ 是特征数量， \n",
    "\n",
    "注意:\n",
    "* 在执行此操作时，请记住变量 `X_train` 和 `y_train` 不是标量值，而是分别为 ($m, n$) 和 ($𝑚$,1) 形状的矩阵，其中 $𝑛$ 是特征和 $𝑚$ 是训练示例的数量。\n",
    "* 对于这一部分，你可以使用上面实现的sigmoid函数。\n",
    "\n",
    "如果你遇到困难，你可以查看下面单元格后提供的提示，以帮助你实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: compute_cost\n",
    "def compute_cost(X, y, w, b, lambda_= 1):\n",
    "    \"\"\"\n",
    "    Computes the cost over all examples\n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "      y : (array_like Shape (m,)) target value \n",
    "      w : (array_like Shape (n,)) Values of parameters of the model      \n",
    "      b : scalar Values of bias parameter of the model\n",
    "      lambda_: unused placeholder\n",
    "    Returns:\n",
    "      total_cost: (scalar)         cost \n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    loss = 0\n",
    "    ### START CODE HERE ###\n",
    "    for i in range(m):\n",
    "     z = np.dot(X, w) + b\n",
    "    f = sigmoid(z)\n",
    "    total_cost = (-y * np.log(f) - (1 - y) * np.log(1 - f)).mean()\n",
    "        \n",
    "        \n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的单元格以检查你对参数 $w$ 的两种不同初始化的 `compute_cost` 函数的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial w (zeros): 0.693\n"
     ]
    }
   ],
   "source": [
    "m, n = X_train.shape\n",
    "\n",
    "# Compute and display cost with w initialized to zeroes\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "cost = compute_cost(X_train, y_train, initial_w, initial_b)\n",
    "print('Cost at initial w (zeros): {:.3f}'.format(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Cost at initial w (zeros)<b></td>\n",
    "    <td> 0.693 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at test w,b: 0.218\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost with non-zero w\n",
    "test_w = np.array([0.2, 0.2])\n",
    "test_b = -24.\n",
    "cost = compute_cost(X_train, y_train, test_w, test_b)\n",
    "\n",
    "print('Cost at test w,b: {:.3f}'.format(cost))\n",
    "\n",
    "\n",
    "# UNIT TESTS\n",
    "compute_cost_test(compute_cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Cost at test w,b<b></td>\n",
    "    <td> 0.218 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.5\"></a>\n",
    "### 2.5 逻辑回归的梯度\n",
    "\n",
    "在本节中，你将实现逻辑回归的梯度。\n",
    "\n",
    "回想一下，梯度下降算法为:\n",
    "\n",
    "$$\\begin{align*}& \\text{repeat until convergence:} \\; \\lbrace \\newline \\; & b := b -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial b} \\newline       \\; & w_j := w_j -  \\alpha \\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} \\tag{1}  \\; & \\text{for j := 0..n-1}\\newline & \\rbrace\\end{align*}$$\n",
    "\n",
    "其中，参数 $b$, $w_j$ 都是同时更新的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a name='ex-03'></a>\n",
    "### 练习 3\n",
    "\n",
    "请完成 `compute_gradient` 函数，用于计算下方的等式（2）和（3） $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$, $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$\n",
    "* m 是数据集中训练样例的数量\n",
    "\n",
    "    \n",
    "*  $f_{\\mathbf{w},b}(x^{(i)})$ 是模型的预测, 其中 $y^{(i)}$ 是实际标签\n",
    "\n",
    "\n",
    "- **注意**: 虽然这个梯度看起来与线性回归梯度相同，但公式实际上是不同的，因为线性和逻辑回归对 $f_{\\mathbf{w},b}(x)$ 有不同的定义。\n",
    "\n",
    "和以前一样，你可以使用你在上面实现的 sigmoid 函数，如果遇到困难，你可以查看下面单元格后面的提示以帮助你实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: compute_gradient\n",
    "def compute_gradient(X, y, w, b, lambda_=None): \n",
    "    \"\"\"\n",
    "    Computes the gradient for logistic regression \n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n)) variable such as house size \n",
    "      y : (array_like Shape (m,1)) actual value \n",
    "      w : (array_like Shape (n,1)) values of parameters of the model      \n",
    "      b : (scalar)                 value of parameter of the model \n",
    "      lambda_: unused placeholder.\n",
    "    Returns\n",
    "      dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b. \n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    dj_dw = np.zeros(w.shape)\n",
    "    dj_db = 0.\n",
    "\n",
    "    ### START CODE HERE ### \n",
    "   # for i in range(m):\n",
    "    z = np.dot(X, w) + b\n",
    "    f = sigmoid(z)\n",
    "    dj_db = (f - y).mean()\n",
    "    dj_dw = ((f - y).reshape(-1,1) * X).mean(axis=0)\n",
    "    \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    # dj_db = (1 / m) * dj_db\n",
    "    # dj_dw = (1 / m) * dj_dw\n",
    "\n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的单元格以检查你对参数 $w$ 的两种不同初始化的 `compute_gradient` 函数的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w (zeros):-0.1\n",
      "dj_dw at initial w (zeros):[-12.00921658929115, -11.262842205513591]\n"
     ]
    }
   ],
   "source": [
    "# Compute and display gradient with w initialized to zeroes\n",
    "initial_w = np.zeros(n)\n",
    "initial_b = 0.\n",
    "\n",
    "dj_db, dj_dw = compute_gradient(X_train, y_train, initial_w, initial_b)\n",
    "print(f'dj_db at initial w (zeros):{dj_db}' )\n",
    "print(f'dj_dw at initial w (zeros):{dj_dw.tolist()}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db at initial w (zeros)<b></td>\n",
    "    <td> -0.1 </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>ddj_dw at initial w (zeros):<b></td>\n",
    "    <td> [-12.00921658929115, -11.262842205513591] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at test_w: -0.5999999999991071\n",
      "dj_dw at test_w: [-44.831353617873795, -44.37384124953978]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Compute and display cost and gradient with non-zero w\n",
    "test_w = np.array([ 0.2, -0.5])\n",
    "test_b = -24\n",
    "dj_db, dj_dw  = compute_gradient(X_train, y_train, test_w, test_b)\n",
    "\n",
    "print('dj_db at test_w:', dj_db)\n",
    "print('dj_dw at test_w:', dj_dw.tolist())\n",
    "\n",
    "# UNIT TESTS    \n",
    "compute_gradient_test(compute_gradient)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db at initial w (zeros)<b></td>\n",
    "    <td> -0.5999999999991071 </td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> <b>ddj_dw at initial w (zeros):<b></td>\n",
    "    <td>  [-44.8313536178737957, -44.37384124953978] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.6\"></a>\n",
    "### 2.6 通过梯度下降法学习参数 \n",
    "\n",
    "与之前的作业类似，你现在将通过使用梯度下降找到逻辑回归模型的最佳参数。\n",
    "- 你不需要为此部分实现任何东西，只需运行下面的单元格。\n",
    "\n",
    "- 验证梯度下降是否正常工作的一个好方法是查看 $J(\\mathbf{w},b)$ 的值，并检查它是否随着每一步而减少。\n",
    " \n",
    "- 假设你已经实现了梯度并正确计算了成本，那么你的 $J(\\mathbf{w},b)$ 的值永远不会增加，并且应该在算法结束时收敛到一个稳定的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters, lambda_): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X :    (array_like Shape (m, n)\n",
    "      y :    (array_like Shape (m,))\n",
    "      w_in : (array_like Shape (n,))  Initial values of parameters of the model\n",
    "      b_in : (scalar)                 Initial value of parameter of the model\n",
    "      cost_function:                  function to compute cost\n",
    "      alpha : (float)                 Learning rate\n",
    "      num_iters : (int)               number of iterations to run gradient descent\n",
    "      lambda_ (scalar, float)         regularization constant\n",
    "      \n",
    "    Returns:\n",
    "      w : (array_like Shape (n,)) Updated values of parameters of the model after\n",
    "          running gradient descent\n",
    "      b : (scalar)                Updated value of parameter of the model after\n",
    "          running gradient descent\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of training examples\n",
    "    m = len(X)\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db, dj_dw = gradient_function(X, y, w_in, b_in, lambda_)   \n",
    "\n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w_in = w_in - alpha * dj_dw               \n",
    "        b_in = b_in - alpha * dj_db              \n",
    "       \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            cost =  cost_function(X, y, w_in, b_in, lambda_)\n",
    "            J_history.append(cost)\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
    "            w_history.append(w_in)\n",
    "            print(f\"Iteration {i:4}: Cost {float(J_history[-1]):8.2f}   \")\n",
    "        \n",
    "    return w_in, b_in, J_history, w_history #return w and J,w history for graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们运行上面的梯度下降算法来学习数据集的参数。\n",
    "\n",
    "**注意**\n",
    "\n",
    "下面的代码块需要几分钟才能运行，尤其是对于非矢量化版本。你可以减少 `iterations` 以测试你的实现并更快地迭代。如果你有时间，请尝试运行 100,000 次迭代以获得更好的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     1.01   \n",
      "Iteration 10000: Cost     0.30   \n",
      "Iteration 20000: Cost     0.30   \n",
      "Iteration 30000: Cost     0.30   \n",
      "Iteration 40000: Cost     0.29   \n",
      "Iteration 50000: Cost     0.29   \n",
      "Iteration 60000: Cost     0.29   \n",
      "Iteration 70000: Cost     0.28   \n",
      "Iteration 80000: Cost     0.28   \n",
      "Iteration 90000: Cost     0.28   \n",
      "Iteration 99999: Cost     0.28   \n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "intial_w = 0.01 * (np.random.rand(2).reshape(-1,1) - 0.5)\n",
    "initial_b = -8\n",
    "\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 100000\n",
    "alpha = 0.001\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(X_train ,y_train, initial_w, initial_b, \n",
    "                                   compute_cost, compute_gradient, alpha, iterations, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <b>预期输出: Cost     0.30, (单击查看细节):</b>\n",
    "</summary>\n",
    "\n",
    "    # With the following settings\n",
    "    np.random.seed(1)\n",
    "    intial_w = 0.01 * (np.random.rand(2).reshape(-1,1) - 0.5)\n",
    "    initial_b = -8\n",
    "    iterations = 10000\n",
    "    alpha = 0.001\n",
    "    #\n",
    "\n",
    "```\n",
    "Iteration    0: Cost     1.01   \n",
    "Iteration 1000: Cost     0.31   \n",
    "Iteration 2000: Cost     0.30   \n",
    "Iteration 3000: Cost     0.30   \n",
    "Iteration 4000: Cost     0.30   \n",
    "Iteration 5000: Cost     0.30   \n",
    "Iteration 6000: Cost     0.30   \n",
    "Iteration 7000: Cost     0.30   \n",
    "Iteration 8000: Cost     0.30   \n",
    "Iteration 9000: Cost     0.30   \n",
    "Iteration 9999: Cost     0.30   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.7\"></a>\n",
    "### 2.7 绘制决策边界\n",
    "\n",
    "我们现在将使用梯度下降的最终参数来绘制线性拟合。如果你正确地实现了前面的部分，你应该看到下面的图\n",
    "<img src=\"images/figure 2.png\"  width=\"450\" height=\"450\">\n",
    "\n",
    "我们将使用 `utils.py` 文件中的辅助函数来创建此图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(w, b, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"2.8\"></a>\n",
    "### 2.8 评估逻辑回归\n",
    "\n",
    "我们可以通过查看学习模型在我们的训练集上的预测效果来评估我们找到的参数的质量。\n",
    "\n",
    "你将在下面实现 `predict` 函数来执行此操作。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-04'></a>\n",
    "### 练习 4\n",
    "\n",
    "请完成 `predict` 函数在给定数据集和学习参数向量 $w$ 和 $b$ 的情况下产生“1”或“0”预测。\n",
    "- 首先，你需要从模型 $f(x^{(i)}) = g(w \\cdot x^{(i)})$ 计算每个示例的预测\n",
    "    - 你之前已经在上面的部分中实现了这一点\n",
    "- 我们将模型的输出 ($f(x^{(i)})$) 解释为给定 $x^{(i)}$ 和参数化的 $w$，$y^{(i)}=1$ 的概率\n",
    "- 因此，要从逻辑回归模型中获得最终预测（$y^{(i)}=0$ 或 $y^{(i)}=1$），你可以使用以下启发式 -\n",
    "\n",
    "  if $f(x^{(i)}) >= 0.5$, predict $y^{(i)}=1$\n",
    "  \n",
    "  if $f(x^{(i)}) < 0.5$, predict $y^{(i)}=0$\n",
    "    \n",
    "如果你遇到困难，你可以查看下面单元格后提供的提示，以帮助你实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(X, w, b): \n",
    "    \"\"\"\n",
    "    Predict whether the label is 0 or 1 using learned logistic\n",
    "    regression parameters w\n",
    "    \n",
    "    Args:\n",
    "    X : (ndarray Shape (m, n))\n",
    "    w : (array_like Shape (n,))      Parameters of the model\n",
    "    b : (scalar, float)              Parameter of the model\n",
    "\n",
    "    Returns:\n",
    "    p: (ndarray (m,1))\n",
    "        The predictions for X using a threshold at 0.5\n",
    "    \"\"\"\n",
    "    # number of training examples\n",
    "    m, n = X.shape   \n",
    "    p = np.zeros(m)\n",
    "   \n",
    "    ### START CODE HERE ### \n",
    "    # Loop over each example\n",
    "    for i in range(m):   \n",
    "     z = np.dot(X, w) + b\n",
    "    f = sigmoid(z)\n",
    "    p = (f >= 0.5).astype(np.int32)\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    ### END CODE HERE ### \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成 `predict` 函数后，让我们运行下面的代码，通过计算正确示例的百分比来报告分类器的训练准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of predict: shape (4,), value [0 1 1 1]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your predict code\n",
    "np.random.seed(1)\n",
    "tmp_w = np.random.randn(2)\n",
    "tmp_b = 0.3    \n",
    "tmp_X = np.random.randn(4, 2) - 0.5\n",
    "\n",
    "tmp_p = predict(tmp_X, tmp_w, tmp_b)\n",
    "print(f'Output of predict: shape {tmp_p.shape}, value {tmp_p}')\n",
    "\n",
    "# UNIT TESTS        \n",
    "predict_test(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出** \n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Output of predict: shape (4,),value [0. 1. 1. 1.]<b></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们用它来计算训练集的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 91.000000\n"
     ]
    }
   ],
   "source": [
    "#Compute accuracy on our training set\n",
    "p = predict(X_train, w,b)\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Train Accuracy (approx):<b></td>\n",
    "    <td> 92.00 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - 逻辑回归的正则化\n",
    "\n",
    "在这部分练习中，你将实施正则化逻辑回归来预测制造厂的微芯片是否通过质量保证 (QA)。在 QA 期间，每个微芯片都会经过各种测试，以确保其正常运行。\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### 3.1 问题描述\n",
    "\n",
    "假设你是工厂的产品经理，你有一些微芯片在两个不同测试中的测试结果。\n",
    "- 从这两个测试中，你想确定微芯片应该被接受还是被拒绝。\n",
    "- 为了帮助你做出决定，你有一个过去微芯片的测试结果数据集，你可以从中构建逻辑回归模型。\n",
    "\n",
    "<a name=\"3.2\"></a>\n",
    "### 3.2 加载与可视化数据\n",
    "\n",
    "与本练习的前面部分类似，让我们首先为此任务加载数据集并对其进行可视化。\n",
    "\n",
    "- 如下所示 `load_dataset()` 函数将数据加载到变量 `X_train` 和 `y_train`\n",
    "  - `X_train` 包含两次测试的微芯片测试结果\n",
    "  - `y_train` 包含 QA 的结果\n",
    "      - `y_train = 1` 表示：微芯片被接受\n",
    "      - `y_train = 0` 表示：微芯片被拒绝\n",
    "  - `X_train` 和 `y_train` 都是 numpy 数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "X_train, y_train = load_data(\"data/ex2data2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看变量\n",
    "\n",
    "下面的代码打印了 `X_train` 和 `y_train` 的前五个值以及变量的类型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[ 0.051267  0.69956 ]\n",
      " [-0.092742  0.68494 ]\n",
      " [-0.21371   0.69225 ]\n",
      " [-0.375     0.50219 ]\n",
      " [-0.51325   0.46564 ]]\n",
      "Type of X_train: <class 'numpy.ndarray'>\n",
      "y_train: [1. 1. 1. 1. 1.]\n",
      "Type of y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# print X_train\n",
    "print(\"X_train:\", X_train[:5])\n",
    "print(\"Type of X_train:\",type(X_train))\n",
    "\n",
    "# print y_train\n",
    "print(\"y_train:\", y_train[:5])\n",
    "print(\"Type of y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 检查变量的维度\n",
    "\n",
    "另一种熟悉数据的有用方法是查看其维度。让我们打印 `X_train` 和 `y_train` 的形状，看看我们的数据集中有多少训练样例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (118, 2)\n",
      "The shape of y_train is: (118,)\n",
      "We have m = 118 training examples\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X_train is: ' + str(X_train.shape))\n",
    "print ('The shape of y_train is: ' + str(y_train.shape))\n",
    "print ('We have m = %d training examples' % (len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可视化数据\n",
    "\n",
    "辅助函数 `plot_data` (来自 `utils.py`) 用于生成如图 3 所示的图形，其中轴是两个测试分数，正面（y = 1，接受）和负面（y = 0，拒绝）示例用不同的标记表示。\n",
    "\n",
    "<img src=\"images/figure 3.png\"  width=\"450\" height=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot examples\n",
    "plot_data(X_train, y_train[:], pos_label=\"Accepted\", neg_label=\"Rejected\")\n",
    "\n",
    "# Set the y-axis label\n",
    "plt.ylabel('Microchip Test 2') \n",
    "# Set the x-axis label\n",
    "plt.xlabel('Microchip Test 1') \n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如图3所示，我们的数据集不能通过图中的直线分为正样本和负样本。因此，逻辑回归的直接应用在该数据集上表现不佳，因为逻辑回归只能找到线性决策边界。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.3\"></a>\n",
    "### 3.3 特征映射\n",
    "\n",
    "更好地拟合数据的一种方法是从每个数据点创建更多特征。在提供的函数 `map_feature` 中，我们将特征映射到 $x_1$ 和 $x_2$ 的所有多项式项，直到六次方。\n",
    "\n",
    "$$\\mathrm{map\\_feature}(x) = \n",
    "\\left[\\begin{array}{c}\n",
    "x_1\\\\\n",
    "x_2\\\\\n",
    "x_1^2\\\\\n",
    "x_1 x_2\\\\\n",
    "x_2^2\\\\\n",
    "x_1^3\\\\\n",
    "\\vdots\\\\\n",
    "x_1 x_2^5\\\\\n",
    "x_2^6\\end{array}\\right]$$\n",
    "\n",
    "作为这种映射的结果，我们的两个特征向量（两个 QA 测试的分数）已被转换为 27 维向量。\n",
    "\n",
    "- 在这个更高维特征向量上训练的逻辑回归分类器将具有更复杂的决策边界，并且在我们的二维图中绘制时将是非线性的。\n",
    "- 我们在 utils.py 中为你提供了 `map_feature` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of data: (118, 2)\n",
      "Shape after feature mapping: (118, 27)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original shape of data:\", X_train.shape)\n",
    "\n",
    "mapped_X =  map_feature(X_train[:, 0], X_train[:, 1])\n",
    "print(\"Shape after feature mapping:\", mapped_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们也打印 `X_train` 和 `mapped X` 的第一个元素来查看转换结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0]: [0.051267 0.69956 ]\n",
      "mapped X_train[0]: [5.12670000e-02 6.99560000e-01 2.62830529e-03 3.58643425e-02\n",
      " 4.89384194e-01 1.34745327e-04 1.83865725e-03 2.50892595e-02\n",
      " 3.42353606e-01 6.90798869e-06 9.42624411e-05 1.28625106e-03\n",
      " 1.75514423e-02 2.39496889e-01 3.54151856e-07 4.83255257e-06\n",
      " 6.59422333e-05 8.99809795e-04 1.22782870e-02 1.67542444e-01\n",
      " 1.81563032e-08 2.47750473e-07 3.38066048e-06 4.61305487e-05\n",
      " 6.29470940e-04 8.58939846e-03 1.17205992e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train[0]:\", X_train[0])\n",
    "print(\"mapped X_train[0]:\", mapped_X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然特征映射允许我们构建更具表现力的分类器，但它也更容易受到过拟合的影响。在练习的下一部分中，你将实施正则化逻辑回归来拟合数据，并亲自了解正则化如何帮助解决过拟合问题。\n",
    "\n",
    "<a name=\"3.4\"></a>\n",
    "### 3.4 正则化逻辑回归的损失函数\n",
    "\n",
    "在这一部分中，你将实现正则化逻辑回归的损失函数。\n",
    "\n",
    "回想一下，对于正则化逻辑回归，损失函数的形式为：\n",
    "$$J(\\mathbf{w},b) = \\frac{1}{m}  \\sum_{i=0}^{m-1} \\left[ -y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m}  \\sum_{j=0}^{n-1} w_j^2$$\n",
    "\n",
    "将其与不带正则化的代价函数（你在上面实现的）进行比较，其形式如下：\n",
    "$$ J(\\mathbf{w}.b) = \\frac{1}{m}\\sum_{i=0}^{m-1} \\left[ (-y^{(i)} \\log\\left(f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - f_{\\mathbf{w},b}\\left( \\mathbf{x}^{(i)} \\right) \\right)\\right]$$\n",
    "\n",
    "不同的是正则化项，即 $$\\frac{\\lambda}{2m} \\sum_{j=0}^{n-1} w_j^2$$\n",
    "请注意，$b$ 参数未正则化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-05'></a>\n",
    "### 练习 5\n",
    "\n",
    "请完成 `compute_cost_reg` 函数为 $w$ 中的每个元素计算以下项\n",
    "$$\\frac{\\lambda}{2m}  \\sum_{j=0}^{n-1} w_j^2$$\n",
    "\n",
    "启动代码将其添加到不带正则化的损失（你在上面的 `compute_cost` 函数中中计算）以计算带正则化的损失。\n",
    "\n",
    "如果你遇到困难，你可以查看下面单元格后提供的提示，以帮助你实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C5\n",
    "def compute_cost_reg(X, y, w, b, lambda_ = 1):\n",
    "    \"\"\"\n",
    "    Computes the cost over all examples\n",
    "    Args:\n",
    "      X : (array_like Shape (m,n)) data, m examples by n features\n",
    "      y : (array_like Shape (m,)) target value \n",
    "      w : (array_like Shape (n,)) Values of parameters of the model      \n",
    "      b : (array_like Shape (n,)) Values of bias parameter of the model\n",
    "      lambda_ : (scalar, float)    Controls amount of regularization\n",
    "    Returns:\n",
    "      total_cost: (scalar)         cost \n",
    "    \"\"\"\n",
    "\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Calls the compute_cost function that you implemented above\n",
    "    cost_without_reg = compute_cost(X, y, w, b) \n",
    "    \n",
    "    # You need to calculate this value\n",
    "    reg_cost = 0.\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    \n",
    "    reg_cost = (w ** 2).sum()\n",
    "    \n",
    "        \n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "    # Add the regularization cost to get the total cost\n",
    "    total_cost = cost_without_reg + (lambda_/(2 * m)) * reg_cost\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的单元格以检查你的“compute_cost_reg”函数的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized cost : 0.6618252552483951\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1]) - 0.5\n",
    "initial_b = 0.5\n",
    "lambda_ = 0.5\n",
    "cost = compute_cost_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(\"Regularized cost :\", cost)\n",
    "\n",
    "# UNIT TEST    \n",
    "compute_cost_reg_test(compute_cost_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Regularized cost : <b></td>\n",
    "    <td> 0.6618252552483948 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.5\"></a>\n",
    "### 3.5 正则化逻辑回归的梯度\n",
    "\n",
    "在本节中，你将实现正则化逻辑回归的梯度。\n",
    "\n",
    "\n",
    "正则化成本函数的梯度有两个分量。第一个，$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$是一个标量，另一个是一个与参数$\\mathbf{w}$形状相同的向量，其中 $j^\\mathrm{th}$ 元素定义如下：\n",
    "\n",
    "$$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b} = \\frac{1}{m}  \\sum_{i=0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})  $$\n",
    "\n",
    "$$\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j} = \\left( \\frac{1}{m}  \\sum_{i=0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) x_j^{(i)} \\right) + \\frac{\\lambda}{m} w_j  \\quad\\, \\mbox{for $j=0...(n-1)$}$$\n",
    "\n",
    "将此与没有正则化的损失函数的梯度（你在上面实现）进行比较，其形式为\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)}) \\tag{2}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - \\mathbf{y}^{(i)})x_{j}^{(i)} \\tag{3}\n",
    "$$\n",
    "\n",
    "\n",
    "如你所见，$\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$ 是一样的,不同之处在下面这一项 $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$, 即 $$\\frac{\\lambda}{m} w_j  \\quad\\, \\mbox{for $j=0...(n-1)$}$$ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-06'></a>\n",
    "### 练习 6\n",
    "\n",
    "请完成 `compute_gradient_reg` 函数，修改代码来计算下面的项\n",
    "\n",
    "$$\\frac{\\lambda}{m} w_j  \\quad\\, \\mbox{for $j=0...(n-1)$}$$\n",
    "\n",
    "启动代码会将此项添加到从上面的 `compute_gradient` 返回的 $\\frac{\\partial J(\\mathbf{w},b)}{\\partial w}$ 中，以获得正则化成本函数的梯度。\n",
    "\n",
    "\n",
    "如果你遇到困难，你可以查看下面单元格后提供的提示，以帮助你实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C6\n",
    "def compute_gradient_reg(X, y, w, b, lambda_ = 1): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    " \n",
    "    Args:\n",
    "      X : (ndarray Shape (m,n))   variable such as house size \n",
    "      y : (ndarray Shape (m,))    actual value \n",
    "      w : (ndarray Shape (n,))    values of parameters of the model      \n",
    "      b : (scalar)                value of parameter of the model  \n",
    "      lambda_ : (scalar,float)    regularization constant\n",
    "    Returns\n",
    "      dj_db: (scalar)             The gradient of the cost w.r.t. the parameter b. \n",
    "      dj_dw: (ndarray Shape (n,)) The gradient of the cost w.r.t. the parameters w. \n",
    "\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "    \n",
    "    dj_db, dj_dw = compute_gradient(X, y, w, b)\n",
    "\n",
    "    ### START CODE HERE ###     \n",
    "    \n",
    "    dj_dw += lambda_ / m * w\n",
    "        \n",
    "        \n",
    "    ### END CODE HERE ###         \n",
    "        \n",
    "    return dj_db, dj_dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下面的单元格以检查你对 `compute_gradient_reg` 函数的实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.07138288792343654\n",
      "First few elements of regularized dj_dw:\n",
      " [-0.010386028450548703, 0.01140985288328012, 0.0536273463274574, 0.0031402782673134602]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "X_mapped = map_feature(X_train[:, 0], X_train[:, 1])\n",
    "np.random.seed(1) \n",
    "initial_w  = np.random.rand(X_mapped.shape[1]) - 0.5 \n",
    "initial_b = 0.5\n",
    " \n",
    "lambda_ = 0.5\n",
    "dj_db, dj_dw = compute_gradient_reg(X_mapped, y_train, initial_w, initial_b, lambda_)\n",
    "\n",
    "print(f\"dj_db: {dj_db}\", )\n",
    "print(f\"First few elements of regularized dj_dw:\\n {dj_dw[:4].tolist()}\", )\n",
    "\n",
    "# UNIT TESTS    \n",
    "compute_gradient_reg_test(compute_gradient_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>dj_db:</b>0.07138288792343656</td> </tr>\n",
    "  <tr>\n",
    "      <td> <b> First few elements of regularized dj_dw:</b> </td> </tr>\n",
    "   <tr>\n",
    "   <td> [[-0.010386028450548701], [0.01140985288328012], [0.0536273463274574], [0.003140278267313462]] </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.6\"></a>\n",
    "### 3.6 通过梯度下降法学习参数\n",
    "\n",
    "与前面部分类似，你将使用上面实现的梯度下降函数来学习最佳参数 $w$,$b$。\n",
    "- 如果你正确完成了正则化逻辑回归的成本和梯度，你应该能够逐步通过下一个单元格来学习参数 $w$。\n",
    "- 训练我们的参数后，我们将使用它来绘制决策边界。\n",
    "\n",
    "**注意**\n",
    "\n",
    "下面的代码块需要相当长的时间才能运行，尤其是对于非矢量化版本。你可以减少 `iterations` 以测试你的实现并更快地迭代。如果你有时间，请运行 100,000 次迭代以查看更好的结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     0.72   \n",
      "Iteration 1000: Cost     0.59   \n",
      "Iteration 2000: Cost     0.56   \n",
      "Iteration 3000: Cost     0.53   \n",
      "Iteration 4000: Cost     0.51   \n",
      "Iteration 5000: Cost     0.50   \n",
      "Iteration 6000: Cost     0.48   \n",
      "Iteration 7000: Cost     0.47   \n",
      "Iteration 8000: Cost     0.46   \n",
      "Iteration 9000: Cost     0.45   \n",
      "Iteration 9999: Cost     0.45   \n"
     ]
    }
   ],
   "source": [
    "# Initialize fitting parameters\n",
    "np.random.seed(1)\n",
    "initial_w = np.random.rand(X_mapped.shape[1])-0.5\n",
    "initial_b = 1.\n",
    "\n",
    "# Set regularization parameter lambda_ to 1 (you can try varying this)\n",
    "lambda_ = 0.01;                                          \n",
    "# Some gradient descent settings\n",
    "iterations = 10000\n",
    "alpha = 0.01\n",
    "\n",
    "w,b, J_history,_ = gradient_descent(X_mapped, y_train, initial_w, initial_b, \n",
    "                                    compute_cost_reg, compute_gradient_reg, \n",
    "                                    alpha, iterations, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <b>预期输出: Cost < 0.5  (Click for details)</b>\n",
    "</summary>\n",
    "\n",
    "```\n",
    "# Using the following settings\n",
    "#np.random.seed(1)\n",
    "#initial_w = np.random.rand(X_mapped.shape[1])-0.5\n",
    "#initial_b = 1.\n",
    "#lambda_ = 0.01;                                          \n",
    "#iterations = 10000\n",
    "#alpha = 0.01\n",
    "Iteration    0: Cost     0.72   \n",
    "Iteration 1000: Cost     0.59   \n",
    "Iteration 2000: Cost     0.56   \n",
    "Iteration 3000: Cost     0.53   \n",
    "Iteration 4000: Cost     0.51   \n",
    "Iteration 5000: Cost     0.50   \n",
    "Iteration 6000: Cost     0.48   \n",
    "Iteration 7000: Cost     0.47   \n",
    "Iteration 8000: Cost     0.46   \n",
    "Iteration 9000: Cost     0.45   \n",
    "Iteration 9999: Cost     0.45       \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.7\"></a>\n",
    "### 3.7 绘制决策边界\n",
    "为了帮助你可视化此分类器学习的模型，我们将使用我们的 `plot_decision_boundary` 函数绘制区分正例和负例的（非线性）决策边界。\n",
    "\n",
    "- 在函数中，我们通过在均匀间隔的网格上计算分类器的预测来绘制非线性决策边界，然后绘制预测从 y = 0 变为 y = 1 的等高线图。\n",
    "\n",
    "- 在学习了参数 $w$,$b$ 之后，下一步是绘制类似于图 4 的决策边界。\n",
    "\n",
    "<img src=\"images/figure 4.png\"  width=\"450\" height=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_decision_boundary(w, b, X_mapped, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3.8\"></a>\n",
    "### 3.8 评估正则化逻辑回归模型\n",
    "\n",
    "你将使用上面实现的 `predict` 函数来计算训练集上的正则逻辑回归模型的准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 82.203390\n"
     ]
    }
   ],
   "source": [
    "#Compute accuracy on the training set\n",
    "p = predict(X_mapped, w, b)\n",
    "\n",
    "print('Train Accuracy: %f'%(np.mean(p == y_train) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预期输出**:\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <b>Train Accuracy:</b>~ 80%</td> </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
